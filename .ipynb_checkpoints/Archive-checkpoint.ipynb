{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_fights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-96fcfe66b9ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_master\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_fights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_fights' is not defined"
     ]
    }
   ],
   "source": [
    "df_master = df_fights.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.drop(['R_KD', 'B_KD', 'R_SIG_STR_pct',\n",
    "       'B_SIG_STR_pct', 'R_TD_pct', 'B_TD_pct', 'R_SUB_ATT', 'B_SUB_ATT',\n",
    "       'R_PASS', 'B_PASS', 'R_REV', 'B_REV', 'win_by', 'last_round',\n",
    "       'last_round_time', 'Format',\n",
    "       'Fight_type', 'R_SIG_STR._ATT', 'R_SIG_STR._LANDED',\n",
    "       'B_SIG_STR._ATT', 'B_SIG_STR._LANDED', 'R_TOTAL_STR._ATT',\n",
    "       'R_TOTAL_STR._LANDED', 'B_TOTAL_STR._ATT', 'B_TOTAL_STR._LANDED',\n",
    "       'R_TD_ATT', 'R_TD_LANDED', 'B_TD_ATT', 'B_TD_LANDED', 'R_HEAD_ATT',\n",
    "       'R_HEAD_LANDED', 'B_HEAD_ATT', 'B_HEAD_LANDED', 'R_BODY_ATT',\n",
    "       'R_BODY_LANDED', 'B_BODY_ATT', 'B_BODY_LANDED', 'R_LEG_ATT',\n",
    "       'R_LEG_LANDED', 'B_LEG_ATT', 'B_LEG_LANDED', 'R_DISTANCE_ATT',\n",
    "       'R_DISTANCE_LANDED', 'B_DISTANCE_ATT', 'B_DISTANCE_LANDED',\n",
    "       'R_CLINCH_ATT', 'R_CLINCH_LANDED', 'B_CLINCH_ATT', 'B_CLINCH_LANDED',\n",
    "       'R_GROUND_ATT', 'R_GROUND_LANDED', 'B_GROUND_ATT', 'B_GROUND_LANDED'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perceptron neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #evaluating dot product during summation\n",
    "\n",
    "class Perceptron(object): #new class to maintain model state\n",
    "\n",
    "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)\n",
    "           \n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        if summation > 0:\n",
    "          activation = 1\n",
    "        else:\n",
    "          activation = 0            \n",
    "        return activation\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.threshold):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
    "                self.weights[0] += self.learning_rate * (label - prediction)\n",
    "                \n",
    "import numpy as np\n",
    "from perceptron import Perceptron\n",
    "\n",
    "training_inputs = X\n",
    "training_inputs.append(np.array([1, 1]))\n",
    "training_inputs.append(np.array([1, 0]))\n",
    "training_inputs.append(np.array([0, 1]))\n",
    "training_inputs.append(np.array([0, 0]))\n",
    "\n",
    "#labels = np.array([1, 0, 0, 0])\n",
    "labels = y\n",
    "\n",
    "perceptron = Perceptron(2)\n",
    "perceptron.train(training_inputs, labels)\n",
    "\n",
    "inputs = np.array([1, 1])\n",
    "perceptron.predict(inputs) \n",
    "#=> 1\n",
    "\n",
    "inputs = np.array([0, 1])\n",
    "perceptron.predict(inputs) \n",
    "#=> 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting classifier to the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbor performs the worst of the algorithms tried\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))  #~0.50\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))  #~0.723a\n",
    "print(\"AUC:\", metrics.roc_auc_score(y_test, y_pred)) #~0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Implement Naive Bayes Classifier using the estimates data</h4>\n",
    "\n",
    "- P(class|data) = (P(data|class) * P(class)) / P(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset by class values, returns a dictionary\n",
    "def separate_by_class(dataset):\n",
    "    separated = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        class_value = vector[5]\n",
    "        if (class_value not in separated):\n",
    "            separated[class_value] = list()\n",
    "        separated[class_value].append(vector)\n",
    "    return separated\n",
    "\n",
    "# Test separating data by class\n",
    "separated = separate_by_class(df_train_est)\n",
    "for label in separated:\n",
    "    print(label)\n",
    "    for row in separated[label]:\n",
    "        print(row)\n",
    "\n",
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "    return sqrt(variance)\n",
    "\n",
    "# Calculate the mean, stdev and count for each column in a dataset\n",
    "def summarize_dataset(dataset):\n",
    "    summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
    "    del(summaries[-1])\n",
    "    return summaries\n",
    "\n",
    "def summarize_by_class(dataset):\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = dict()\n",
    "    for class_value, rows in separated.items():\n",
    "        summaries[class_value] = summarize_dataset(rows)\n",
    "    return summaries\n",
    "\n",
    "from math import pi\n",
    "from math import exp\n",
    " \n",
    "# Calculate the Gaussian probability distribution function for x\n",
    "    #f(x) = (1 / sqrt(2 * PI) * sigma) * exp(-((x-mean)^2 / (2 * sigma^2)))\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
    "\n",
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    probabilities = dict()\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev, _ = class_summaries[i]\n",
    "            probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "    return probabilities\n",
    " \n",
    "# Calculate class probabilities\n",
    "summaries = summarize_by_class(df_train_est)\n",
    "probabilities = calculate_class_probabilities(summaries, df_train_est[0])\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
