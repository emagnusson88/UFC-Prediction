{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_fights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-96fcfe66b9ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_master\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_fights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_fights' is not defined"
     ]
    }
   ],
   "source": [
    "df_master = df_fights.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.drop(['R_KD', 'B_KD', 'R_SIG_STR_pct',\n",
    "       'B_SIG_STR_pct', 'R_TD_pct', 'B_TD_pct', 'R_SUB_ATT', 'B_SUB_ATT',\n",
    "       'R_PASS', 'B_PASS', 'R_REV', 'B_REV', 'win_by', 'last_round',\n",
    "       'last_round_time', 'Format',\n",
    "       'Fight_type', 'R_SIG_STR._ATT', 'R_SIG_STR._LANDED',\n",
    "       'B_SIG_STR._ATT', 'B_SIG_STR._LANDED', 'R_TOTAL_STR._ATT',\n",
    "       'R_TOTAL_STR._LANDED', 'B_TOTAL_STR._ATT', 'B_TOTAL_STR._LANDED',\n",
    "       'R_TD_ATT', 'R_TD_LANDED', 'B_TD_ATT', 'B_TD_LANDED', 'R_HEAD_ATT',\n",
    "       'R_HEAD_LANDED', 'B_HEAD_ATT', 'B_HEAD_LANDED', 'R_BODY_ATT',\n",
    "       'R_BODY_LANDED', 'B_BODY_ATT', 'B_BODY_LANDED', 'R_LEG_ATT',\n",
    "       'R_LEG_LANDED', 'B_LEG_ATT', 'B_LEG_LANDED', 'R_DISTANCE_ATT',\n",
    "       'R_DISTANCE_LANDED', 'B_DISTANCE_ATT', 'B_DISTANCE_LANDED',\n",
    "       'R_CLINCH_ATT', 'R_CLINCH_LANDED', 'B_CLINCH_ATT', 'B_CLINCH_LANDED',\n",
    "       'R_GROUND_ATT', 'R_GROUND_LANDED', 'B_GROUND_ATT', 'B_GROUND_LANDED'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perceptron neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #evaluating dot product during summation\n",
    "\n",
    "class Perceptron(object): #new class to maintain model state\n",
    "\n",
    "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)\n",
    "           \n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        if summation > 0:\n",
    "          activation = 1\n",
    "        else:\n",
    "          activation = 0            \n",
    "        return activation\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.threshold):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
    "                self.weights[0] += self.learning_rate * (label - prediction)\n",
    "                \n",
    "import numpy as np\n",
    "from perceptron import Perceptron\n",
    "\n",
    "training_inputs = X\n",
    "training_inputs.append(np.array([1, 1]))\n",
    "training_inputs.append(np.array([1, 0]))\n",
    "training_inputs.append(np.array([0, 1]))\n",
    "training_inputs.append(np.array([0, 0]))\n",
    "\n",
    "#labels = np.array([1, 0, 0, 0])\n",
    "labels = y\n",
    "\n",
    "perceptron = Perceptron(2)\n",
    "perceptron.train(training_inputs, labels)\n",
    "\n",
    "inputs = np.array([1, 1])\n",
    "perceptron.predict(inputs) \n",
    "#=> 1\n",
    "\n",
    "inputs = np.array([0, 1])\n",
    "perceptron.predict(inputs) \n",
    "#=> 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting classifier to the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbor performs the worst of the algorithms tried\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))  #~0.50\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))  #~0.723a\n",
    "print(\"AUC:\", metrics.roc_auc_score(y_test, y_pred)) #~0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Support Vector Machine implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X=df_train_est[['location', 'title_bout',\n",
    "       'R_Height', 'R_Weight', 'R_Reach', 'R_KD', 'R_SIG_STR_pct', 'R_TD_pct',\n",
    "       'R_SUB_ATT', 'R_PASS', 'R_REV', 'R_SIG_STR._ATT', 'R_SIG_STR._LANDED',\n",
    "       'R_TOTAL_STR._ATT', 'R_TOTAL_STR._LANDED', 'R_TD_ATT', 'R_TD_LANDED',\n",
    "       'R_HEAD_ATT', 'R_HEAD_LANDED', 'R_BODY_ATT', 'R_BODY_LANDED',\n",
    "       'R_LEG_ATT', 'R_LEG_LANDED', 'R_DISTANCE_ATT', 'R_DISTANCE_LANDED',\n",
    "       'R_CLINCH_ATT', 'R_CLINCH_LANDED', 'R_GROUND_ATT', 'R_GROUND_LANDED',\n",
    "       'R_total_time_fought(sec)', 'R_no_of_rounds', 'R_KO_win_%',\n",
    "       'R_Sub_win_%', 'R_Stance_Orthodox', 'R_Stance_Southpaw', 'R_num_fights',\n",
    "       'R_record', 'R_age', 'B_Height', 'B_Weight', 'B_Reach', 'B_KD',\n",
    "       'B_SIG_STR_pct', 'B_TD_pct', 'B_SUB_ATT', 'B_PASS', 'B_REV',\n",
    "       'B_SIG_STR._ATT', 'B_SIG_STR._LANDED', 'B_TOTAL_STR._ATT',\n",
    "       'B_TOTAL_STR._LANDED', 'B_TD_ATT', 'B_TD_LANDED', 'B_HEAD_ATT',\n",
    "       'B_HEAD_LANDED', 'B_BODY_ATT', 'B_BODY_LANDED', 'B_LEG_ATT',\n",
    "       'B_LEG_LANDED', 'B_DISTANCE_ATT', 'B_DISTANCE_LANDED', 'B_CLINCH_ATT',\n",
    "       'B_CLINCH_LANDED', 'B_GROUND_ATT', 'B_GROUND_LANDED',\n",
    "       'B_total_time_fought(sec)', 'B_no_of_rounds', 'B_KO_win_%',\n",
    "       'B_Sub_win_%', 'B_Stance_Orthodox', 'B_Stance_Southpaw', 'B_num_fights',\n",
    "       'B_record', 'B_age', 'Bantamweight', 'Featherweight', 'Flyweight',\n",
    "       'Heavyweight', 'Light Heavyweight', 'Lightweight', 'Middleweight',\n",
    "       'Welterweight', 'Women\\'s Bantamweight', 'Women\\'s Featherweight',\n",
    "       'Women\\'s Flyweight', 'Women\\'s Strawweight']]  # Features\n",
    "\n",
    "y=df_train_est['Red_win']  # Labels\n",
    "\n",
    "#X, y = make_classification(n_features=4, random_state=0)\n",
    "clf = make_pipeline(StandardScaler(), LinearSVC(random_state=0, tol=1e-5))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 80% training and 20% test\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "predicted_classes = clf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test,predicted_classes)\n",
    "#parameters = clf.coef_\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted_classes))  #when we pred a winner, how often were we right?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, predicted_classes)) #what % of our winner preds were right\n",
    "print(\"Recall:\",metrics.recall_score(y_test, predicted_classes)) #what % of winners did we detect\n",
    "print(\"AUC:\", metrics.roc_auc_score(y_test, predicted_classes)) #area under ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Implement Naive Bayes Classifier using the estimates data</h4>\n",
    "\n",
    "- P(class|data) = (P(data|class) * P(class)) / P(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset by class values, returns a dictionary\n",
    "def separate_by_class(dataset):\n",
    "    separated = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        class_value = vector[5]\n",
    "        if (class_value not in separated):\n",
    "            separated[class_value] = list()\n",
    "        separated[class_value].append(vector)\n",
    "    return separated\n",
    "\n",
    "# Test separating data by class\n",
    "separated = separate_by_class(df_train_est)\n",
    "for label in separated:\n",
    "    print(label)\n",
    "    for row in separated[label]:\n",
    "        print(row)\n",
    "\n",
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "    return sqrt(variance)\n",
    "\n",
    "# Calculate the mean, stdev and count for each column in a dataset\n",
    "def summarize_dataset(dataset):\n",
    "    summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
    "    del(summaries[-1])\n",
    "    return summaries\n",
    "\n",
    "def summarize_by_class(dataset):\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = dict()\n",
    "    for class_value, rows in separated.items():\n",
    "        summaries[class_value] = summarize_dataset(rows)\n",
    "    return summaries\n",
    "\n",
    "from math import pi\n",
    "from math import exp\n",
    " \n",
    "# Calculate the Gaussian probability distribution function for x\n",
    "    #f(x) = (1 / sqrt(2 * PI) * sigma) * exp(-((x-mean)^2 / (2 * sigma^2)))\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
    "\n",
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    probabilities = dict()\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev, _ = class_summaries[i]\n",
    "            probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "    return probabilities\n",
    " \n",
    "# Calculate class probabilities\n",
    "summaries = summarize_by_class(df_train_est)\n",
    "probabilities = calculate_class_probabilities(summaries, df_train_est[0])\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Other Models</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Implement Random Forest Classifier for the estimates data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_train_est[['location', 'title_bout',\n",
    "       'R_Height', 'R_Weight', 'R_Reach', 'R_KD', 'R_SIG_STR_pct', 'R_TD_pct',\n",
    "       'R_SUB_ATT', 'R_PASS', 'R_REV', 'R_SIG_STR._ATT', 'R_SIG_STR._LANDED',\n",
    "       'R_TOTAL_STR._ATT', 'R_TOTAL_STR._LANDED', 'R_TD_ATT', 'R_TD_LANDED',\n",
    "       'R_HEAD_ATT', 'R_HEAD_LANDED', 'R_BODY_ATT', 'R_BODY_LANDED',\n",
    "       'R_LEG_ATT', 'R_LEG_LANDED', 'R_DISTANCE_ATT', 'R_DISTANCE_LANDED',\n",
    "       'R_CLINCH_ATT', 'R_CLINCH_LANDED', 'R_GROUND_ATT', 'R_GROUND_LANDED',\n",
    "       'R_total_time_fought(sec)', 'R_no_of_rounds', 'R_KO_win_%',\n",
    "       'R_Sub_win_%', 'R_Stance_Orthodox', 'R_Stance_Southpaw', 'R_num_fights',\n",
    "       'R_record', 'R_age', 'B_Height', 'B_Weight', 'B_Reach', 'B_KD',\n",
    "       'B_SIG_STR_pct', 'B_TD_pct', 'B_SUB_ATT', 'B_PASS', 'B_REV',\n",
    "       'B_SIG_STR._ATT', 'B_SIG_STR._LANDED', 'B_TOTAL_STR._ATT',\n",
    "       'B_TOTAL_STR._LANDED', 'B_TD_ATT', 'B_TD_LANDED', 'B_HEAD_ATT',\n",
    "       'B_HEAD_LANDED', 'B_BODY_ATT', 'B_BODY_LANDED', 'B_LEG_ATT',\n",
    "       'B_LEG_LANDED', 'B_DISTANCE_ATT', 'B_DISTANCE_LANDED', 'B_CLINCH_ATT',\n",
    "       'B_CLINCH_LANDED', 'B_GROUND_ATT', 'B_GROUND_LANDED',\n",
    "       'B_total_time_fought(sec)', 'B_no_of_rounds', 'B_KO_win_%',\n",
    "       'B_Sub_win_%', 'B_Stance_Orthodox', 'B_Stance_Southpaw', 'B_num_fights',\n",
    "       'B_record', 'B_age', 'Bantamweight', 'Featherweight', 'Flyweight',\n",
    "       'Heavyweight', 'Light Heavyweight', 'Lightweight', 'Middleweight',\n",
    "       'Welterweight', 'Women\\'s Bantamweight', 'Women\\'s Featherweight',\n",
    "       'Women\\'s Flyweight', 'Women\\'s Strawweight']]  # Features\n",
    "\n",
    "y=df_train_est['Red_win']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 80% training and 20% test\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))  #~0.65\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred)) #what % of our winner preds were right\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred)) #what % of winners did we detect\n",
    "print(\"AUC:\", metrics.roc_auc_score(y_test, y_pred))\n",
    "\n",
    "#SCORES:\n",
    "Accuracy: 0.6662420382165605\n",
    "Precision: 0.6830357142857143\n",
    "Recall: 0.9035433070866141\n",
    "AUC: 0.5672951192472782"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- implement logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "X=df_train_est[['location', 'title_bout',\n",
    "       'R_Height', 'R_Weight', 'R_Reach', 'R_KD', 'R_SIG_STR_pct', 'R_TD_pct',\n",
    "       'R_SUB_ATT', 'R_PASS', 'R_REV', 'R_SIG_STR._ATT', 'R_SIG_STR._LANDED',\n",
    "       'R_TOTAL_STR._ATT', 'R_TOTAL_STR._LANDED', 'R_TD_ATT', 'R_TD_LANDED',\n",
    "       'R_HEAD_ATT', 'R_HEAD_LANDED', 'R_BODY_ATT', 'R_BODY_LANDED',\n",
    "       'R_LEG_ATT', 'R_LEG_LANDED', 'R_DISTANCE_ATT', 'R_DISTANCE_LANDED',\n",
    "       'R_CLINCH_ATT', 'R_CLINCH_LANDED', 'R_GROUND_ATT', 'R_GROUND_LANDED',\n",
    "       'R_total_time_fought(sec)', 'R_no_of_rounds', 'R_KO_win_%',\n",
    "       'R_Sub_win_%', 'R_Stance_Orthodox', 'R_Stance_Southpaw', 'R_num_fights',\n",
    "       'R_record', 'R_age', 'B_Height', 'B_Weight', 'B_Reach', 'B_KD',\n",
    "       'B_SIG_STR_pct', 'B_TD_pct', 'B_SUB_ATT', 'B_PASS', 'B_REV',\n",
    "       'B_SIG_STR._ATT', 'B_SIG_STR._LANDED', 'B_TOTAL_STR._ATT',\n",
    "       'B_TOTAL_STR._LANDED', 'B_TD_ATT', 'B_TD_LANDED', 'B_HEAD_ATT',\n",
    "       'B_HEAD_LANDED', 'B_BODY_ATT', 'B_BODY_LANDED', 'B_LEG_ATT',\n",
    "       'B_LEG_LANDED', 'B_DISTANCE_ATT', 'B_DISTANCE_LANDED', 'B_CLINCH_ATT',\n",
    "       'B_CLINCH_LANDED', 'B_GROUND_ATT', 'B_GROUND_LANDED',\n",
    "       'B_total_time_fought(sec)', 'B_no_of_rounds', 'B_KO_win_%',\n",
    "       'B_Sub_win_%', 'B_Stance_Orthodox', 'B_Stance_Southpaw', 'B_num_fights',\n",
    "       'B_record', 'B_age', 'Bantamweight', 'Featherweight', 'Flyweight',\n",
    "       'Heavyweight', 'Light Heavyweight', 'Lightweight', 'Middleweight',\n",
    "       'Welterweight', 'Women\\'s Bantamweight', 'Women\\'s Featherweight',\n",
    "       'Women\\'s Flyweight', 'Women\\'s Strawweight']]  # Features\n",
    "\n",
    "y=df_train_est['Red_win']  # Labels\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "predicted_classes = model.predict(X)\n",
    "accuracy = accuracy_score(y.values.flatten(),predicted_classes)\n",
    "parameters = model.coef_\n",
    "\n",
    "accuracy #logistic regression yields 0.6656 accuracy\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y.values.flatten(), predicted_classes))  #when we pred a winner, how often were we right?\n",
    "print(\"Precision:\",metrics.precision_score(y.values.flatten(), predicted_classes)) #what % of our winner preds were right\n",
    "print(\"Recall:\",metrics.recall_score(y.values.flatten(), predicted_classes)) #what % of winners did we detect\n",
    "print(\"AUC:\", metrics.roc_auc_score(y.values.flatten(), predicted_classes)) #area under ROC curve\n",
    "\n",
    "#SCORES:\n",
    "Accuracy: 0.6754140127388535\n",
    "Precision: 0.6991766941101963\n",
    "Recall: 0.8720379146919431\n",
    "AUC: 0.5950282897221382"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Multi-layer perceptron neural network</h4>\n",
    "\n",
    "- scale training features to (-1,1) range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X=df_train_est[['location', 'title_bout',\n",
    "       'R_Height', 'R_Weight', 'R_Reach', 'R_KD', 'R_SIG_STR_pct', 'R_TD_pct',\n",
    "       'R_SUB_ATT', 'R_PASS', 'R_REV', 'R_SIG_STR._ATT', 'R_SIG_STR._LANDED',\n",
    "       'R_TOTAL_STR._ATT', 'R_TOTAL_STR._LANDED', 'R_TD_ATT', 'R_TD_LANDED',\n",
    "       'R_HEAD_ATT', 'R_HEAD_LANDED', 'R_BODY_ATT', 'R_BODY_LANDED',\n",
    "       'R_LEG_ATT', 'R_LEG_LANDED', 'R_DISTANCE_ATT', 'R_DISTANCE_LANDED',\n",
    "       'R_CLINCH_ATT', 'R_CLINCH_LANDED', 'R_GROUND_ATT', 'R_GROUND_LANDED',\n",
    "       'R_total_time_fought(sec)', 'R_no_of_rounds', 'R_KO_win_%',\n",
    "       'R_Sub_win_%', 'R_Stance_Orthodox', 'R_Stance_Southpaw', 'R_num_fights',\n",
    "       'R_record', 'R_age', 'B_Height', 'B_Weight', 'B_Reach', 'B_KD',\n",
    "       'B_SIG_STR_pct', 'B_TD_pct', 'B_SUB_ATT', 'B_PASS', 'B_REV',\n",
    "       'B_SIG_STR._ATT', 'B_SIG_STR._LANDED', 'B_TOTAL_STR._ATT',\n",
    "       'B_TOTAL_STR._LANDED', 'B_TD_ATT', 'B_TD_LANDED', 'B_HEAD_ATT',\n",
    "       'B_HEAD_LANDED', 'B_BODY_ATT', 'B_BODY_LANDED', 'B_LEG_ATT',\n",
    "       'B_LEG_LANDED', 'B_DISTANCE_ATT', 'B_DISTANCE_LANDED', 'B_CLINCH_ATT',\n",
    "       'B_CLINCH_LANDED', 'B_GROUND_ATT', 'B_GROUND_LANDED',\n",
    "       'B_total_time_fought(sec)', 'B_no_of_rounds', 'B_KO_win_%',\n",
    "       'B_Sub_win_%', 'B_Stance_Orthodox', 'B_Stance_Southpaw', 'B_num_fights',\n",
    "       'B_record', 'B_age', 'Bantamweight', 'Featherweight', 'Flyweight',\n",
    "       'Heavyweight', 'Light Heavyweight', 'Lightweight', 'Middleweight',\n",
    "       'Welterweight', 'Women\\'s Bantamweight', 'Women\\'s Featherweight',\n",
    "       'Women\\'s Flyweight', 'Women\\'s Strawweight']]  # Features\n",
    "\n",
    "y=df_train_est['Red_win']  # Labels\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X, y = make_classification(n_samples=100, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1, test_size=0.2)\n",
    "\n",
    "#mlp = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300\n",
    "                    , activation='relu', solver='lbfgs', warm_start=False\n",
    "                    , early_stopping=False, validation_fraction=0.1).fit(X_train, y_train)\n",
    "\n",
    "mlp.predict_proba(X_test[:1])\n",
    "mlp.predict(X_test[:5, :])\n",
    "mlp.score(X_test, y_test) #Returns the mean accuracy on the given test data and labels\n",
    "\n",
    "#SCORE: 0.5821656050955414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "#principalDf = pd.DataFrame(data = principalComponents\n",
    " #            , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = mlp.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, AUC=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('False Positive rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.title('ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUC:\", metrics.roc_auc_score(y_test,  y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Feature Selection</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_stan = sc.fit_transform(X_train)\n",
    "\n",
    "clf_stan = SVC(kernel ='rbf', gamma = 'auto', probability=True)\n",
    "clf_stan.fit(X_train_stan, y_train) \n",
    "\n",
    "selector = SelectFromModel(estimator=clf_stan).fit(X_train_stan, y_train)\n",
    "selector.transform(X_train_stan)\n",
    "\n",
    "#print(clf_stan.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import sklearn's feature selection algorithm \n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#model = LogisticRegression() \n",
    "\n",
    "rfe = RFE(clf, 3)\n",
    "\n",
    "fit = rfe.fit(X, y)\n",
    "\n",
    "print(\"Num Features: %d\"% fit.n_features_)\n",
    "print(\"Selected Features: %s\"% fit.support_)\n",
    "print(\"Feature Ranking: %s\"% fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X=df_train_est[['location', 'title_bout',\n",
    "       'R_Height', 'R_Weight', 'R_Reach', 'R_KD', 'R_SIG_STR_pct', 'R_TD_pct',\n",
    "       'R_SUB_ATT', 'R_PASS', 'R_REV', 'R_SIG_STR._ATT', 'R_SIG_STR._LANDED',\n",
    "       'R_TOTAL_STR._ATT', 'R_TOTAL_STR._LANDED', 'R_TD_ATT', 'R_TD_LANDED',\n",
    "       'R_HEAD_ATT', 'R_HEAD_LANDED', 'R_BODY_ATT', 'R_BODY_LANDED',\n",
    "       'R_LEG_ATT', 'R_LEG_LANDED', 'R_DISTANCE_ATT', 'R_DISTANCE_LANDED',\n",
    "       'R_CLINCH_ATT', 'R_CLINCH_LANDED', 'R_GROUND_ATT', 'R_GROUND_LANDED',\n",
    "       'R_total_time_fought(sec)', 'R_no_of_rounds', 'R_KO_win_%',\n",
    "       'R_Sub_win_%', 'R_Stance_Orthodox', 'R_Stance_Southpaw', 'R_num_fights',\n",
    "       'R_record', 'R_age', 'B_Height', 'B_Weight', 'B_Reach', 'B_KD',\n",
    "       'B_SIG_STR_pct', 'B_TD_pct', 'B_SUB_ATT', 'B_PASS', 'B_REV',\n",
    "       'B_SIG_STR._ATT', 'B_SIG_STR._LANDED', 'B_TOTAL_STR._ATT',\n",
    "       'B_TOTAL_STR._LANDED', 'B_TD_ATT', 'B_TD_LANDED', 'B_HEAD_ATT',\n",
    "       'B_HEAD_LANDED', 'B_BODY_ATT', 'B_BODY_LANDED', 'B_LEG_ATT',\n",
    "       'B_LEG_LANDED', 'B_DISTANCE_ATT', 'B_DISTANCE_LANDED', 'B_CLINCH_ATT',\n",
    "       'B_CLINCH_LANDED', 'B_GROUND_ATT', 'B_GROUND_LANDED',\n",
    "       'B_total_time_fought(sec)', 'B_no_of_rounds', 'B_KO_win_%',\n",
    "       'B_Sub_win_%', 'B_Stance_Orthodox', 'B_Stance_Southpaw', 'B_num_fights',\n",
    "       'B_record', 'B_age', 'Bantamweight', 'Featherweight', 'Flyweight',\n",
    "       'Heavyweight', 'Light Heavyweight', 'Lightweight', 'Middleweight',\n",
    "       'Welterweight', 'Women\\'s Bantamweight', 'Women\\'s Featherweight',\n",
    "       'Women\\'s Flyweight', 'Women\\'s Strawweight']]  # Features\n",
    "\n",
    "y=df_train_est['Red_win']  # Labels\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))  #when we pred a winner, how often were we right?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred)) #what % of our winner preds were right\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred)) #what % of winners did we detect\n",
    "print(\"F1:\",metrics.f1_score(y_test, y_pred)) #harmonic mean of precision and recall\n",
    "print(\"AUC:\", metrics.roc_auc_score(y_test, y_pred)) #area under ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import sklearn's feature selection algorithm \n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#model = LogisticRegression() \n",
    "\n",
    "rfe = RFE(clf, 3)\n",
    "\n",
    "fit = rfe.fit(X, y)\n",
    "\n",
    "print(\"Num Features: %d\"% fit.n_features_)\n",
    "print(\"Selected Features: %s\"% fit.support_)\n",
    "print(\"Feature Ranking: %s\"% fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Scraper Additions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "from typing import List, Dict, Tuple\n",
    "from createdata.make_soup import make_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_EVENTS_URL = 'http://ufcstats.com/statistics/events/completed?page=all'\n",
    "BASE_PATH = Path(os.getcwd())/'data'\n",
    "EVENT_AND_FIGHT_LINKS_PATH = BASE_PATH/'event_and_fight_links.pickle'\n",
    "PAST_EVENT_LINKS_PATH = BASE_PATH/'past_event_links.pickle'\n",
    "\n",
    "def get_link_of_past_events(all_events_url: str=ALL_EVENTS_URL) -> List[str]:\n",
    "    links = []\n",
    "    url = all_events_url\n",
    "    soup = make_soup(qall_events_url)\n",
    "    for link in soup.findAll('td',{'class': 'b-statistics__table-col'}):\n",
    "        for href in link.findAll('a'):\n",
    "            foo = href.get('href')\n",
    "            links.append(foo)\n",
    "    #pickle_out = open(PAST_EVENT_LINKS_PATH.as_posix(),\"wb\")\n",
    "    #pickle.dump(links, pickle_out)\n",
    "    #pickle_out.close()\n",
    "\n",
    "    return links\n",
    "\n",
    "new_scraped_links = get_link_of_past_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previously_scraped_event_links = pickle.load(open(PAST_EVENT_LINKS_PATH.as_posix(), \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_scraped_links)\n",
    "new_scraped_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(previously_scraped_event_links)\n",
    "previously_scraped_event_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "main_list = np.setdiff1d(new_scraped_links,previously_scraped_event_links)\n",
    "main_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(PAST_EVENT_LINKS_PATH.as_posix(), \"rb\" ).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(os.getcwd())/'data'\n",
    "#CSV_PATH = BASE_PATH/'fighter_details.csv'\n",
    "PAST_FIGHTER_LINKS_PATH = BASE_PATH/'fighter_links.pickle'\n",
    "\n",
    "past_fighter_links=[]\n",
    "\n",
    "pickle_out = open(PAST_FIGHTER_LINKS_PATH.as_posix(),\"wb\")\n",
    "pickle.dump(past_fighter_links, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Scraping Upcoming Bouts</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "from typing import List, Dict, Tuple\n",
    "from createdata.make_soup import make_soup\n",
    "import numpy as np\n",
    "\n",
    "ALL_EVENTS_URL = 'http://ufcstats.com/statistics/events/completed?page=all'\n",
    "UPCOMING_EVENTS_URL = 'http://ufcstats.com/statistics/events/upcoming?page=all'\n",
    "BASE_PATH = Path(os.getcwd())/'data'\n",
    "EVENT_AND_FIGHT_LINKS_PATH = BASE_PATH/'event_and_fight_links.pickle'\n",
    "PAST_EVENT_LINKS_PATH = BASE_PATH/'past_event_links.pickle'\n",
    "\n",
    "def get_link_of_past_events(all_events_url: str=ALL_EVENTS_URL) -> List[str]:\n",
    "    links = []\n",
    "    url = all_events_url\n",
    "    soup = make_soup(all_events_url)\n",
    "    for link in soup.findAll('td',{'class': 'b-statistics__table-col'}):\n",
    "        for href in link.findAll('a'):\n",
    "            foo = href.get('href')\n",
    "            links.append(foo)\n",
    "    pickle_out = open(PAST_EVENT_LINKS_PATH.as_posix(),\"wb\")\n",
    "    pickle.dump(links, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    return links\n",
    "\n",
    "def get_event_and_fight_links(event_links: List[str]) -> Dict[str, List[str]]:\n",
    "    event_and_fight_links = {}\n",
    "    for link in event_links:\n",
    "        event_fights = []\n",
    "        soup = make_soup(link)\n",
    "        for row in soup.findAll('tr', {'class': 'b-fight-details__table-row b-fight-details__table-row__hover js-fight-details-click'}):\n",
    "            href = row.get('data-link')\n",
    "            event_fights.append(href)\n",
    "        event_and_fight_links[link] = event_fights\n",
    "\n",
    "    pickle_out = open(EVENT_AND_FIGHT_LINKS_PATH.as_posix(),\"wb\")\n",
    "    pickle.dump(event_and_fight_links, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    return event_and_fight_links\n",
    "\n",
    "def get_all_links() -> Dict[str, List[str]]:\n",
    "    if EVENT_AND_FIGHT_LINKS_PATH.exists()!=True:\n",
    "        if PAST_EVENT_LINKS_PATH.exists()!=True:\n",
    "            past_event_links = get_link_of_past_events()\n",
    "        else:\n",
    "            pickle_in = open(PAST_EVENT_LINKS_PATH.as_posix(),\"rb\")\n",
    "            past_event_links = pickle.load(pickle_in)\n",
    "            pickle_in.close()\n",
    "        event_and_fight_links = get_event_and_fight_links(past_event_links)\n",
    "    else:\n",
    "        pickle_in = open(EVENT_AND_FIGHT_LINKS_PATH.as_posix(),\"rb\")\n",
    "        event_and_fight_links = pickle.load(pickle_in)\n",
    "        pickle_in.close()\n",
    "\n",
    "    return event_and_fight_links\n",
    "################################\n",
    "def get_link_of_past_events_no_pickle(all_events_url: str=ALL_EVENTS_URL) -> List[str]:\n",
    "    links = []\n",
    "    url = all_events_url\n",
    "    soup = make_soup(all_events_url)\n",
    "    for link in soup.findAll('td',{'class': 'b-statistics__table-col'}):\n",
    "        for href in link.findAll('a'):\n",
    "            foo = href.get('href')\n",
    "            links.append(foo)\n",
    "\n",
    "    return links\n",
    "\n",
    "def get_link_of_upcoming_events_no_pickle(upcoming_events_url: str=UPCOMING_EVENTS_URL) -> List[str]:\n",
    "    links = []\n",
    "    url = upcoming_events_url\n",
    "    soup = make_soup(upcoming_events_url)\n",
    "    for link in soup.findAll('td',{'class': 'b-statistics__table-col'}):\n",
    "        for href in link.findAll('a'):\n",
    "            foo = href.get('href')\n",
    "            links.append(foo)\n",
    "\n",
    "    return links\n",
    "\n",
    "def get_event_and_fight_links_no_pickle(event_links: List[str]) -> Dict[str, List[str]]:\n",
    "    event_and_fight_links = {}\n",
    "    for link in event_links:\n",
    "        event_fights = []\n",
    "        soup = make_soup(link)\n",
    "        for row in soup.findAll('tr', {'class': 'b-fight-details__table-row b-fight-details__table-row__hover js-fight-details-click'}):\n",
    "            href = row.get('data-link')\n",
    "            event_fights.append(href)\n",
    "        event_and_fight_links[link] = event_fights\n",
    "\n",
    "    return event_and_fight_links\n",
    "\n",
    "def get_all_new_links() -> Dict[str, List[str]]:\n",
    "    if EVENT_AND_FIGHT_LINKS_PATH.exists()!=True:\n",
    "        if PAST_EVENT_LINKS_PATH.exists()!=True:\n",
    "            past_event_links = get_link_of_past_events()\n",
    "        else:\n",
    "            pickle_in = open(PAST_EVENT_LINKS_PATH.as_posix(),\"rb\")\n",
    "            past_event_links = pickle.load(pickle_in)\n",
    "            pickle_in.close()\n",
    "        event_and_fight_links = get_event_and_fight_links(past_event_links)\n",
    "    else:\n",
    "\n",
    "        pickle_in = open(PAST_EVENT_LINKS_PATH.as_posix(),\"rb\")\n",
    "        past_event_links = pickle.load(pickle_in)\n",
    "\n",
    "        new_event_links = get_link_of_past_events_no_pickle()\n",
    "\n",
    "        event_and_fight_links = get_event_and_fight_links_no_pickle(np.setdiff1d(new_event_links,past_event_links))\n",
    "\n",
    "        pickle_in.close()\n",
    "\n",
    "        #set event links to the newly scraped list\n",
    "        pickle_out = open(PAST_EVENT_LINKS_PATH.as_posix(),\"wb\")\n",
    "        pickle.dump(new_event_links, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "    return event_and_fight_links\n",
    "\n",
    "def get_upcoming_links() -> Dict[str, List[str]]:\n",
    "\n",
    "    upcoming_event_links = get_link_of_upcoming_events_no_pickle()\n",
    "    upcoming_event_and_fight_links = get_event_and_fight_links_no_pickle(upcoming_event_links)\n",
    "\n",
    "    return upcoming_event_and_fight_links\n",
    "\n",
    "###############################3333\n",
    "\n",
    "def get_this_event_fight_links(event_links: List[str]) -> Dict[str, List[str]]:\n",
    "    if isinstance(event_links, list):\n",
    "        return get_event_and_fight_links(event_links)\n",
    "    else:\n",
    "        return get_event_and_fight_links(list[event_links])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from typing import \tList, Dict, Tuple\n",
    "from pathlib import Path\n",
    "import os\n",
    "from createdata.print_progress import print_progress\n",
    "from createdata.make_soup import make_soup\n",
    "\n",
    "HEADER_upcoming: str = 'R_fighter;B_fighter;Format;date;location\\n'\n",
    "BASE_PATH = Path(os.getcwd())/'data'\n",
    "\n",
    "def get_upcoming_fight_details(fight_soup: BeautifulSoup) -> str:\n",
    "    columns = ''\n",
    "    for div in fight_soup.findAll('div', {'class':'b-fight-details'}):\n",
    "        for col in div.findAll('h3', {'class': 'b-fight-details__person-name'}):\n",
    "            if columns == '':\n",
    "                columns = col.text\n",
    "            else:\n",
    "                columns = columns + ',' +(col.text)\n",
    "                \n",
    "        for col in div.findAll('i', {'class': 'b-fight-details__fight-title'}):\n",
    "            if columns == '':\n",
    "                columns = col.text\n",
    "            else:\n",
    "                columns = columns + ',' +(col.text)\n",
    "                \n",
    "    columns = columns.replace('  ', '').replace('\\n\\n\\n\\n', ',')\\\n",
    "    .replace('\\n', '').replace(', ', ',').replace(' ,',',')\n",
    "    .replace('Method: ', '').replace('Round:', '').replace('Time:', '')\\\n",
    "    .replace('Time format:', '').replace('Referee:', '')\n",
    "\n",
    "    fight_details = ';'.join(columns.split(',')[:5])\n",
    "\n",
    "    return fight_details\n",
    "\n",
    "#working\n",
    "def get_event_info(event_soup: BeautifulSoup) -> str:\n",
    "    event_info = ''\n",
    "    for info in event_soup.findAll('li', {'class':'b-list__box-list-item'}):\n",
    "        if event_info == '':\n",
    "            event_info = (info.text)\n",
    "        else:\n",
    "            event_info = event_info + ';' + info.text\n",
    "\n",
    "    event_info = ';'.join(event_info.replace('Date:','').replace('Location:','')\\\n",
    "        .replace('Attendance:','').replace('\\n','').replace('  ', '').split(';')[:2])\n",
    "\n",
    "    return event_info\n",
    "\n",
    "def get_upcoming_fight_stats(event_and_fight_links: Dict[str, List[str]]) -> str:\n",
    "    total_stats = ''\n",
    "\n",
    "    l = len(event_and_fight_links)\n",
    "    print('Scraping upcoming fight data: ')\n",
    "    print_progress(0, l, prefix = 'Progress:', suffix = 'Complete')\n",
    "\n",
    "    for index, (event,fights) in enumerate(event_and_fight_links.items()):\n",
    "        event_soup = make_soup(event)\n",
    "        event_info = get_event_info(event_soup)\n",
    "\n",
    "        for fight in fights:\n",
    "            try:\n",
    "                fight_soup = make_soup(fight)\n",
    "                fight_details = get_upcoming_fight_details(fight_soup)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "            total_upcoming_info = fight_details + ';' + event_info\n",
    "\n",
    "            if total_stats == '':\n",
    "                total_stats = total_upcoming_info\n",
    "            else:\n",
    "                total_stats = total_stats + '\\n' + total_upcoming_info\n",
    "\n",
    "        print_progress(index + 1, l, prefix = 'Progress:', suffix = 'Complete')\n",
    "\n",
    "    return total_stats\n",
    "\n",
    "def create_upcoming_fight_data_csv(upcoming_event_and_fight_links: Dict[str, List[str]],\n",
    "                        filename: str = 'upcoming_fight_data.csv', header: str = HEADER_upcoming) -> None:\n",
    "\n",
    "    CSV_PATH = BASE_PATH/filename\n",
    "    #assert CSV_PATH.exists()!=True, 'filename exists'\n",
    "    total_stats = get_upcoming_fight_stats(upcoming_event_and_fight_links)\n",
    "\n",
    "    if CSV_PATH.exists()!=True:\n",
    "        with open(CSV_PATH.as_posix(), 'a') as file:\n",
    "            #file.write(bytes(header, encoding='ascii', errors='ignore'))\n",
    "            file.write(bytes(total_stats, encoding='ascii', errors='ignore'))\n",
    "    else:\n",
    "        with open(CSV_PATH.as_posix(), 'wb') as file:\n",
    "            file.write(bytes(header, encoding='ascii', errors='ignore'))\n",
    "            file.write(bytes(total_stats, encoding='ascii', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming_links = get_upcoming_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pri(upcoming_event_and_fight_links: Dict[str, List[str]],\n",
    "                        filename: str = 'upcoming_fight_data.csv', header: str = HEADER_upcoming) -> None:\n",
    "\n",
    "    total_stats = get_upcoming_fight_stats(upcoming_event_and_fight_links)\n",
    "    print(total_stats)\n",
    "\n",
    "pri(upcoming_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_upcoming_fight_data_csv(upcoming_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>PCA for SVM</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=12)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
